{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e42a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from typing import Literal\n",
    "\n",
    "def count_tokens(\n",
    "    text: str,\n",
    "    provider: Literal[\"openai\", \"anthropic\"],\n",
    "    *,\n",
    "    model: str | None = None,\n",
    ") -> int:\n",
    "    \"\"\"\n",
    "    Return the number of tokens `text` would use with the chosen provider.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    text      : The string you want to measure.\n",
    "    provider  : \"openai\" or \"anthropic\".\n",
    "    model     : (optional) A specific model name.\n",
    "                • OpenAI – defaults to \"gpt-3.5-turbo\".\n",
    "                • Anthropic – only needed if you plan to call the\n",
    "                  beta messages‐style counter.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    • OpenAI token rules differ by model family; we pick the correct\n",
    "      encoding automatically and fall back to ``cl100k_base`` if the\n",
    "      model is unknown. :contentReference[oaicite:0]{index=0}  \n",
    "    • Anthropic’s Python SDK exposes a simple ``client.count_tokens()``\n",
    "      helper for plain strings and a richer\n",
    "      ``client.beta.messages.count_tokens()`` for structured prompts. :contentReference[oaicite:1]{index=1}\n",
    "    \"\"\"\n",
    "    provider = provider.lower()\n",
    "\n",
    "    if provider == \"openai\":\n",
    "        import tiktoken\n",
    "\n",
    "        model = model or \"gpt-3.5-turbo\"\n",
    "        try:\n",
    "            enc = tiktoken.encoding_for_model(model)   # provider-specific BPE\n",
    "        except KeyError:                               # unknown model → default\n",
    "            enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "        return len(enc.encode(text))\n",
    "\n",
    "    elif provider == \"anthropic\":\n",
    "        from anthropic import Anthropic\n",
    "\n",
    "        client = Anthropic()           # uses ANTHROPIC_API_KEY if set\n",
    "        return client.messages.count_tokens(\n",
    "            model=\"claude-3-7-sonnet-20250219\",\n",
    "            messages=[{\"role\": \"user\", \"content\": text}]\n",
    "        ).input_tokens\n",
    "        \n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"provider must be 'openai' or 'anthropic'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5565ae86",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tokens(\"Test\", provider=\"anthropic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e899c617",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tokens(StudentAgent().get_output_jsonschema().__str__(), provider=\"anthropic\")\n",
    "count_tokens(StudentAgent().get_output_jsonschema().__str__(), provider=\"openai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213d2df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mllm.config.default_models.normal"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
